{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up -- do not change\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.1 (6 pts)\n",
    "\n",
    "> In this question, we extend the cue combination observer model seen in class with a prior.\n",
    "\n",
    "We consider here the standard model of cue combination modeling an audio-visual estimation experiment like the one seen in class and represented in Figure 5.1 of \\[**MKG23**\\]. All values are measured in degrees of visual angle.\n",
    "\n",
    "- Differently from the cue combination cases we considered before, here we introduce a Gaussian prior, $p(s) = \\mathcal{N}\\left(s; \\mu_s, \\sigma_s^2 \\right)$.\n",
    "- For the rest, we assume the usual setup with two conditionally independent Gaussian measurements, $x_i \\sim \\mathcal{N}\\left(x_i | s_i, \\sigma_i^2\\right)$ for $i = 1,2$ (with audio = 1 and visual = 2).\n",
    "- As usual, we also postulate that the observer believes that $s_1 = s_2 = s$, so that their posterior is:\n",
    "$$\n",
    "p(s|x_1, x_2) \\propto p(s) p(x_1|s) p(x_2|s).\n",
    "$$\n",
    "- We ignore motor noise (i.e, $r = \\hat{s}$, or equivalently $\\sigma_\\text{motor} = 0$ deg). In other words, the estimate distribution is equivalent to the response distribution $p(\\hat{s}|s_1, s_2) = p(r|s_1, s_2)$. *Note*: This is not relevant for part a, but only for part b of this exercise.\n",
    "\n",
    "Throughout the exercise, we assume the following model parameters:\n",
    "$$\n",
    "\\mu_s = 1 \\text{ deg}, \\; \\sigma_s = 2 \\text{ deg}, \\quad \\sigma_1 = 2 \\text{ deg}, \\; \\sigma_2 = 3 \\text{ deg}.\n",
    "$$\n",
    "\n",
    "- a) Compute the observer's posterior distribution $p(s|x_1,x_2)$ for $x_1 = 3, x_2 = -1$ deg. Report the posterior mean $\\mu_\\text{post}$ and standard deviation $\\sigma_\\text{post}$ in Moodle.\n",
    "- b) Compute the observer's estimate distribution $p(\\hat{s}|s_1, s_2)$ for $s_1 = 6, s_2 = 0$ deg, assuming they use the posterior mean estimate $\\hat{s}_\\text{PM} = \\mu_\\text{post}$ (as per the model described above). Report the estimate distribution mean $\\mu_\\text{est}$ and standard deviation $\\sigma_\\text{est}$ in Moodle.\n",
    "\n",
    "*Hints*: \n",
    "- Be careful that in this case (non-flat prior), the variance of the estimate distribution $\\sigma_\\text{est}^2$ is *not* equal to the posterior variance $\\sigma_\\text{post}^2$.\n",
    "- For this exercise, it might be convenient to use the precision representation from the book, using $J = \\frac{1}{\\sigma^2}$.\n",
    "- You are asked to get to the results analytically, thus report your solutions up to numerical precision. For exercise (b), simulation results within $\\pm 0.01$ from the correct solution will be accepted, but will only give half points. Numerical integration will not work for part (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a):\n",
    "In order to finds the the posterior mean $\\mu_\\text{post}$ and standard deviation $\\sigma_\\text{post}$ we can do the steps as follows:\n",
    "\n",
    "$$\n",
    "{Prior:}\n",
    "p(s) = N(s; \\mu_s, \\sigma_s^2)\n",
    "$$\n",
    "\n",
    "$${Likelihoods:}\n",
    "p(x_1 | s) = N(x_1 | s, \\sigma_1^2) \\quad \\text{and} \\quad p(x_2 | s) = N(x_2 | s, \\sigma_2^2)\n",
    "$$\n",
    "\n",
    "$${Posterior:}\n",
    "p(s | x_1, x_2) \\propto p(s) p(x_1|s) p(x_2|s)\n",
    "$$\n",
    "\n",
    "As it said in the question the prior is non-flat. For simplicity we can precision representation.\n",
    "\n",
    "The weights $w_s$, $w_1$, and $w_2$ are defined as:\n",
    "\n",
    "- For $w_s$:\n",
    "$$\n",
    "w_s = \\frac{J_s}{J_s + J_1 + J_2},\n",
    "$$\n",
    "\n",
    "- For $w_1$:\n",
    "$$\n",
    "w_1 = \\frac{J_1}{J_s + J_1 + J_2},\n",
    "$$\n",
    "\n",
    "- For $w_2$:\n",
    "$$\n",
    "w_2 = \\frac{J_2}{J_s + J_1 + J_2},\n",
    "$$\n",
    "\n",
    "where $J_s = \\frac{1}{\\sigma_s^2}$, $J_1 = \\frac{1}{\\sigma_1^2}$ and  $J_2 = \\frac{1}{\\sigma_2^2}$.\n",
    "\n",
    "So the posterior mean can be expressed as a linear combination of the prior mean and the sensory measurements.\n",
    "\n",
    "$$\n",
    "\\mu_{\\text{post}} = w_s \\mu_s + w_1x_1 + w_2x_2\n",
    "$$\n",
    "\n",
    "The total precision of the posterior $J_{\\text{post}}$ is given by:\n",
    "\n",
    "$$\n",
    "J_{\\text{post}} = J_s + J_1 + J_2\n",
    "$$\n",
    "\n",
    "\n",
    "So the posterior variance is:\n",
    "$$\n",
    "\\sigma_{\\text{post}}^2 = \\frac{1}{J_{\\text{post}}}\n",
    "$$\n",
    "\n",
    "And we can derive the posterior Standard Deviation $\\sigma_{\\text{post}}$** as:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\text{post}} = \\sqrt{\\sigma_{\\text{post}}^2} = \\frac{1}{\\sqrt{J_{\\text{post}}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The posterior mean value is : 1.4545454545454544\n",
      "The posterior standard deviation value is : 1.2792042981336627\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "mu_s = 1 \n",
    "sigma_s = 2 \n",
    "sigma1 = 2  # Standard deviation of the first cue (audio)\n",
    "sigma2 = 3  # Standard deviation of the second cue (visual)\n",
    "x1 = 3 \n",
    "x2 = -1  \n",
    "\n",
    "# Precisions\n",
    "J_s = 1 / sigma_s**2\n",
    "J_1 = 1 / sigma1**2\n",
    "J_2 = 1 / sigma2**2\n",
    "J_total = J_s + J_1 + J_2\n",
    "\n",
    "# Weights\n",
    "w_s = J_s / J_total\n",
    "w_1 = J_1 / J_total\n",
    "w_2 = J_2 / J_total\n",
    "\n",
    "# Posterior mean \n",
    "mu_post = w_s * mu_s + w_1 * x1 + w_2 * x2\n",
    "\n",
    "# Posterior standard deviation\n",
    "sigma_post = (1 / J_total)**0.5\n",
    "\n",
    "print('The posterior mean value is : {}'.format(mu_post))\n",
    "print('The posterior standard deviation value is : {}'.format(sigma_post))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b):\n",
    "In order to find the mean and the standard deviation for estimation destribution, we can use this fact that $\\hat{s}$ is a linear function of $x_1$ and $x_2$, and $x_1$ and $x_2$ are (indepedent) Gaussian random variables, so $\\hat{s}$ is Gaussian as well with mean and variance:\n",
    "\n",
    "\n",
    "$$\\mathbb{E}\\left[\\hat{s} | s_1, s_2\\right] = \\mathbb{E}\\left[w_s \\mu_{\\text{post}} + w_1 x_1 + w_2 x_2 | s_1, s_2\\right] \\\\\n",
    "= w_s \\mu_{\\text{post}} + w_1 \\mathbb{E}\\left[x_1 | s_1, s_2\\right] + w_2 \\mathbb{E}\\left[x_2 | s_1, s_2\\right] \\\\\n",
    "= w_s \\mu_{\\text{post}} + w_1 s_1 + w_2 s_2$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Var}\\left[\\hat{s} | s_1, s_2\\right] = \\text{Var}\\left[w_s \\mu_{\\text{post}} + w_1 x_1 + w_2 x_2 | s_1, s_2\\right] \\\\\n",
    "= w_s^2 \\text{Var}\\left[\\mu_{\\text{post}}\\right] + w_1^2 \\text{Var}\\left[x_1 | s_1, s_2\\right] + w_2^2 \\text{Var}\\left[x_2 | s_1, s_2\\right] \\\\\n",
    "= 0 + w_1^2 \\sigma_1^2 + w_2^2 \\sigma_2^2 \\\\\n",
    "= w_1^2 \\sigma_1^2 + w_2^2 \\sigma_2^2\n",
    "$$\n",
    "\n",
    "According to the definition of variance, the variance of $\\mu_{\\text{post}}$ is zero since it is a scalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated distribution mean is : 2.8636363636363633\n",
      "The estimated distribution standard deviation is : 0.9833321660356333\n"
     ]
    }
   ],
   "source": [
    "s1 = 6\n",
    "s2 = 0\n",
    "\n",
    "#  estimate distribution mean\n",
    "mu_est= w_s * mu_s + w_1 * s1 + w_2 * s2\n",
    "\n",
    "# estimate distribution standard deviation\n",
    "sigma_est = np.sqrt(w_1**2 * sigma1**2 + w_2**2 * sigma2**2)\n",
    "\n",
    "print('The estimated distribution mean is : {}'.format(mu_est))\n",
    "print('The estimated distribution standard deviation is : {}'.format(sigma_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.2 (6 pts)\n",
    "\n",
    "> In this problem, we can now use our knowledge to fit data from a real audio-visual cue combination experiment!\n",
    "\n",
    "The data have been preprocessed for the purpose of this exercise. We use here the `simplecue` model, defined below:\n",
    "\n",
    "- We assume an observer with a flat prior $p(s) = 1$ (i.e., \"no prior\").\n",
    "- The measurement noise for the auditory stimulus is $p(x_1|s_1) = \\mathcal{N}(x_1|s_1, \\sigma_{1}^2)$, as usual. \n",
    "- In this experiment, there are *two* possible levels for the visual noise, *low* noise (`0`) and *high* noise (`1`). Experimentally, the visual stimulus is made \"noisier\" in a trial by blurring and/or reducing the contrast the stimulus. So, the measurement noise for the visual stimulus depends on the visual noise level in the trial, such that\n",
    "  $$\\mathcal{N}(x_2|s_2, \\sigma_{2,\\text{low}}^2) \\text{ if noise_level is 0,} \\qquad \\text{and} \\qquad\n",
    "  \\mathcal{N}(x_2|s_2, \\sigma_{2,\\text{high}}^2) \\text{ if noise_level is 1}.\n",
    "  $$\n",
    "- We assume that the observer is aware of the noise level in each trial.\n",
    "- As usual in simple cue combination, the observer believes that $s_1 = s_2 = s$.\n",
    "- The observer reports the posterior mean estimate $\\hat{s}_\\text{PM}$. We assume zero motor noise ($r = \\hat{s}$ and $\\sigma_\\text{motor} = 0$).\n",
    "- The model parameters are thus $\\theta = \\left(\\sigma_1, \\sigma_{2,\\text{low}}, \\sigma_{2,\\text{high}} \\right)$.\n",
    "\n",
    "We analyze a dataset of audiovisual estimation data from a single subject.\n",
    "The dataset consists of a table with four columns, where each row represents a trial of the experiment. The four columns are:\n",
    "- The location of the auditory stimulus `s1` (in deg).\n",
    "- The location of the visual stimulus `s2` (in deg).\n",
    "- The noise level of the visual stimulus `noise_level`, here `0` (low noise) or `1` (high noise). \n",
    "- The observer's response `r` (in deg).\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "- a) As a sanity check, compute the log-likelihood of the full dataset for model parameters $\\theta_0 = (\\sigma_1 = 4, \\sigma_{2,\\text{low}} = 6, \\sigma_{2,\\text{high}} = 8)$ and report the result in Moodle.\n",
    "- b) Fit the model above to the data using maximum-likelihood esimation (MLE). Report in Moodle the log-likelihood at the MLE solution.\n",
    "\n",
    "*Hint*:\n",
    "- In part (a), you should find that $-2050 < \\log \\mathcal{L}(\\theta_0) < -2000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data of audiovisual cue combination experiment from .csv file\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lacerbi/prob-cog-mod-files/main/data/avcue_data.csv')\n",
    "df = df.to_numpy()\n",
    "s1 = df[:,0]\n",
    "s2 = df[:,1]\n",
    "noise_level = df[:,2].astype(int)\n",
    "r = df[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a):\n",
    "According to the information in the question, the auditory and visual stimuli are assumed to be perceived with Gaussian noise, represented by:\n",
    "\n",
    "- For the auditory stimulus:\n",
    "$$\n",
    "p(x_1 | s_1) = N(x_1 | s_1, \\sigma_1^2)\n",
    "$$\n",
    "where $\\sigma_1^2$ is the variance of the auditory noise.\n",
    "\n",
    "- For the visual stimulus:\n",
    "$$\n",
    "p(x_2 | s_2) = N(x_2 | s_2, \\sigma_2^2)\n",
    "$$\n",
    "where $\\sigma_2^2$ is the variance of the visual noise.\n",
    "\n",
    "The posterior mean estimate $\\hat{s}_{\\text{PM}}$ combines the information from both the auditory and visual cues. Assuming a flat prior ($p(s) = 1$), the posterior mean is a weighted average of the cues, where the weights are proportional to their precisions:\n",
    "\n",
    "$$\n",
    "\\hat{s}_{\\text{PM}} = \\frac{J_1 s_1 + J_2 s_2}{J_1 + J_2}\n",
    "$$\n",
    "\n",
    "The log-likelihood of an observer's response $r$ given the model parameters is based on the Gaussian probability density function. The variance in the observer's response is effectively the inverse of the total precision from both cues:\n",
    "\n",
    "$$\n",
    "\\text{variance} = \\frac{1}{J_1 + J_2}\n",
    "$$\n",
    "\n",
    "Finally, the log-likelihood for a single observation is given by:\n",
    "\n",
    "$$\n",
    "-\\frac{1}{2} \\log(2\\pi \\times \\text{variance}) - \\frac{1}{2} \\frac{(r - \\hat{s}_{\\text{PM}})^2}{\\text{variance}}\n",
    "$$\n",
    "\n",
    "where $\\hat{s}_{\\text{PM}}$ is the posterior mean estimate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total log-likelihood of the dataset using precision: -2034.6551809030655\n"
     ]
    }
   ],
   "source": [
    "# Model parameters \n",
    "sigma1 = 4  \n",
    "sigma2_low = 6  \n",
    "sigma2_high = 8  \n",
    "\n",
    "J1 = 1 / sigma1**2 \n",
    "J2_low = 1 / sigma2_low**2\n",
    "J2_high = 1 / sigma2_high**2\n",
    "\n",
    "def posterior_mean(s1, s2, J1, J2):\n",
    "    weighted_sum = J1 * s1 + J2 * s2\n",
    "    total = J1 + J2\n",
    "    return weighted_sum / total\n",
    "\n",
    "\n",
    "def log_likelihood(s1, s2, r, noise_level, J1, J2_low, J2_high):\n",
    "    J2 = J2_low if noise_level == 0 else J2_high\n",
    "    s_hat = posterior_mean(s1, s2, J1, J2)\n",
    "    total= J1 + J2\n",
    "    variance = 1 / total  \n",
    "    return -0.5 * np.log(2 * np.pi * variance) - 0.5 * ((r - s_hat)**2 / variance)\n",
    "\n",
    "# Compute the log-likelihood for each trial and sum them up\n",
    "total_log_likelihood = np.sum([log_likelihood(s1[i], s2[i], r[i], noise_level[i], J1, J2_low, J2_high) for i in range(len(s1))])\n",
    "\n",
    "print(\"Total log-likelihood of the dataset using precision:\", total_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bads:TooCloseBounds: For each variable, hard and plausible bounds should not be too close. Moving plausible bounds.\n",
      "Variables (index) internally transformed to log coordinates: [[0 0]\n",
      " [0 1]\n",
      " [0 2]]\n",
      "MLE Parameters: sigma1 = 9.231196983173485, sigma2_low = 4.63302604731058, sigma2_high = 6.78174305495014\n",
      "Log-likelihood at MLE solution is : -1604.1495487423465\n"
     ]
    }
   ],
   "source": [
    "def total_log_likelihood(params, s1, s2, r, noise_level):\n",
    "    sigma1, sigma2_low, sigma2_high = params\n",
    "    J1 = 1 / sigma1**2\n",
    "    J2_low = 1 / sigma2_low**2\n",
    "    J2_high = 1 / sigma2_high**2\n",
    "    \n",
    "    log_likelihood_sum = 0\n",
    "    for i in range(len(s1)):\n",
    "        log_likelihood_sum += log_likelihood(s1[i], s2[i], r[i], noise_level[i], J1, J2_low, J2_high)\n",
    "    return log_likelihood_sum\n",
    "\n",
    "# Define the function to minimize \n",
    "def neg_total_log_likelihood(params):\n",
    "    return -total_log_likelihood(params, s1, s2, r, noise_level)\n",
    "\n",
    "use_pybads = True\n",
    "initial_params = [4, 6, 8]  \n",
    "\n",
    "if use_pybads:\n",
    "    from pybads.bads import BADS\n",
    "    \n",
    "    plausible_lower_bounds = [0.1, 0.1, 0.1]  \n",
    "    plausible_upper_bounds = [20, 20, 20]  \n",
    "    \n",
    "    optimizer = BADS(neg_total_log_likelihood, initial_params, \n",
    "                     lower_bounds=plausible_lower_bounds,\n",
    "                     upper_bounds=plausible_upper_bounds)\n",
    "    result = sp.optimize.minimize(neg_total_log_likelihood, initial_params, method='L-BFGS-B', bounds=[(0.1, None), (0.1, None), (0.1, None)])\n",
    "    mle_params = result.x\n",
    "\n",
    "    print(\"MLE Parameters: sigma1 = {}, sigma2_low = {}, sigma2_high = {}\".format(mle_params[0], mle_params[1], mle_params[2]))\n",
    "\n",
    "    mle_log_likelihood = total_log_likelihood(mle_params, s1, s2, r, noise_level)\n",
    "    print(\"Log-likelihood at MLE solution is : {}\".format(mle_log_likelihood))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.3 (6 pts)\n",
    "\n",
    "> In this question, we consider learning the probability of a binary event through noisy measurements. A similar task is used in behavioral tasks with humans and animals to explore the nature of decision making (see notes).\n",
    "\n",
    "We consider here the following decision-making task:\n",
    "\n",
    "- In each trial of the task, the observer needs to press an arrow key depending on whether they are shown a left-tilted or a right-tilted grating on a screen.\n",
    "- In each trial $i$, the grating orientation $s_i$ is either -1 (left) or 1 (right), with $p(s_i = 1|\\pi_\\text{R}) = \\pi_\\text{R}$ and $p(s_i = -1|\\pi_\\text{R}) = 1 - \\pi_\\text{R}$, where $\\pi_\\text{R} \\in (0, 1)$ is the probability of the grating being right-tilted.\n",
    "- The observer only sees a noisy measurement of orientation $x_i$, with $p(x_i|s_i) = \\mathcal{N}\\left(x_i|s_i,\\sigma^2\\right)$. In this exercise, we assume $\\sigma = 1$.\n",
    "- Assume the observer starts with a flat prior over $\\pi_\\text{R}$, that is $p(\\pi_\\text{R}) = 1$ for $\\pi_\\text{R} \\in (0, 1)$.\n",
    "\n",
    "Compute numerically the posterior $p(\\pi_\\text{R}|\\textbf{x}_\\text{obs})$ that the Bayesian observer would have after having observed the full sequence of noisy measurements $\\textbf{x}_\\text{obs} = \\left(x_1, \\ldots, x_T\\right)$ provided below (assuming no feedback is given to the subject). Report in Moodle the mean and standard deviation of the posterior over $\\pi_\\text{R}$ at the end of the last trial $T$.\n",
    "\n",
    "\n",
    "*Hint*: Given the posterior $ p(\\pi_\\text{R}| x_1,\\ldots, x_{t-1})$ at the end of the previous trial $t-1$ (where $t = 0$ is the prior), you can compute the posterior at trial $t$ as\n",
    "$$\n",
    "p(\\pi_\\text{R} | x_1, \\ldots, x_t) \\propto p(\\pi_\\text{R}| x_1,\\ldots, x_{t-1}) \\left[ p(x_{t}| s_t = 1) p(s_{t} = 1|\\pi_\\text{R}) + p(x_{t}| s_t = -1) p(s_{t} = -1|\\pi_\\text{R})\\right],\n",
    "$$\n",
    "where all the terms are defined above.\n",
    "\n",
    "*Notes*: \n",
    "- A similar task is being used with mice by the [International Brain Laboratory](https://www.internationalbrainlab.com/#home) to explore the nature of decision making (see [this paper](https://elifesciences.org/articles/63711)). The experiments show that, after training, mice adapt their responses according to changes of $\\pi_\\text{R}$ across experimental blocks. A key question is how the probability $\\pi_\\text{R}$ is represented in the mouse brain (if explicitly represented at all).\n",
    "- Of course, when analyzing actual experimental data we would not have access to $\\mathbf{x}_\\text{obs}$, and we would need to marginalize over it given the (known to us) sequence of stimuli, but this is not required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = np.array([ 0.82757179,  0.12214158,  1.04221375,  1.58281521, -0.10061918,\n",
    "        2.14472371,  1.90159072,  1.50249434,  1.90085595,  0.31627214,\n",
    "        0.87710977,  0.06423057,  0.73211192, -0.46964453,  0.30833925,\n",
    "        0.60324647,  0.3128273 ,  0.15479436,  0.32875387,  0.9873354 ,\n",
    "       -2.11731035, -0.7655843 ,  2.65980218,  1.74204416, -1.19183555,\n",
    "       -1.88762896,  0.25284171,  2.6924546 ,  1.05080775, -1.63699565])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The posterior mean is : 0.7665069446447835\n",
      "The posterior standard deviation is : 0.09999268626235762\n"
     ]
    }
   ],
   "source": [
    "pi_R = np.linspace(0, 1, 1000)\n",
    "prior = np.ones_like(pi_R)  # Flat prior\n",
    "\n",
    "# Update function for the posterior\n",
    "def update_posterior(prior, x, pi_R):\n",
    "    likelihood_right = sps.norm.pdf(x, 1, 1)  # p(x|s=1)\n",
    "    likelihood_left = sps.norm.pdf(x, -1, 1)  # p(x|s=-1)\n",
    "    posterior = prior * (likelihood_right * pi_R + likelihood_left * (1 - pi_R)) \n",
    "    return posterior / np.sum(posterior)  # Normalize\n",
    "\n",
    "# Update the posterior distribution iteratively for each observation in x_obs\n",
    "posterior = prior\n",
    "for x in x_obs:\n",
    "    posterior = update_posterior(posterior, x, pi_R)\n",
    "\n",
    "# Compute mean and standard deviation of the posterior distribution\n",
    "mean_pi_R = np.sum(posterior * pi_R)\n",
    "std_pi_R = np.sqrt(np.sum(posterior * (pi_R - mean_pi_R)**2))\n",
    "\n",
    "print('The posterior mean is : {}'.format(mean_pi_R))\n",
    "print('The posterior standard deviation is : {}'.format(std_pi_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the mean of the posterior over $\\pi_R$ is 0.767 and the standard deviation is 0.099 which means based on the observed data, the bayesian observer estimates that there is a roughly 76.7% chance that the grating is right-tilted, with a standard deviation of 9.99% reflecting the uncertainty in this estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.4 (7 pts)\n",
    "\n",
    "> In this question, we examine how subjects might learn a Gaussian prior over stimuli, which is a common occurrence in many psychophysical experiments.\n",
    "\n",
    "We assume that the observer is simultaneously learning both the mean $\\mu_s$ and the standard deviation $\\sigma_s$ of the prior. We denote with $q_s(s)$ the observer's prior (as opposed to the true experimental distribution of stimuli, $p_s(s)$).\n",
    "\n",
    "For example, we could consider the \"coin catching\" task of \\[**BVK10**\\] described in Week 6 and Exercise 6.2, but the details do not particularly matter. What matters is that in each trial the observer sees stimulus $s \\sim p(s) = \\mathcal{N}\\left(s| \\mu_s, \\sigma_s^2\\right)$ (we ignore measurement noise). We assume the observer learns the parameters of the distribution $p_s(s)$ over multiple trials.\n",
    "\n",
    "Assume that the observer starts with a factorized prior over $\\mu_s$ and $\\sigma_s$:\n",
    "$$\n",
    "p(\\mu_s, \\sigma_s) = p(\\mu_s) p(\\sigma_s) = \\mathcal{N}\\left(\\mu_s; 0, \\tau^2 \\right) \\frac{1}{\\tau} \\exp\\left[-\\frac{\\sigma_s}{\\tau} \\right] \\qquad \\text{ for } \\; \\sigma_s > 0,\n",
    "$$\n",
    "where $\\tau = 0.1$.\n",
    "\n",
    "Take the sequence of stimuli $\\textbf{s}$ computed below. Compute the posterior $p(\\mu_s, \\sigma_s| s_1, \\ldots, s_t)$, with the simplifying assumption that the observer has direct access to $s_i$ at the end of each trial. Compute the posterior mean of the observer's prior mean $\\hat{\\mu_s}_{PM}$ and the posterior mean of the observer's prior standard deviation $\\hat{\\sigma_s}_{PM}$ as a function of trial $t$, where $t = 0$ is before the start of the experiment (prior), $t = 1$ is the end of the first trial, and so on up to $t = T$.\n",
    "\n",
    "- a) Report in Moodle the posterior means of the observer's prior parameters, $\\hat{\\mu_s}_\\text{PM}$ and $\\hat{\\sigma_s}_\\text{PM}$, after the $T$ observations.\n",
    "- b) Plot the posterior mean $\\hat{\\mu_s}_\\text{PM}$ and $\\hat{\\sigma_s}_\\text{PM}$ as a function of $t = 0, \\ldots, T$. You should see that that $\\hat{\\mu_s}_\\text{PM}$ increases with time, while $\\hat{\\sigma_s}_\\text{PM}$ has an initial spike upwards, and then decreases over time. Can you explain why? Write your answer below and report it in Moodle (max 200 words).\n",
    "\n",
    "*Hints*:\n",
    "- For part (a), you will need a 2-D grid to keep track of the posterior over $\\mu_s$ and $\\sigma_s$ across iterations.\n",
    "- Since $\\sigma_s > 0$, start the grid for $\\sigma_s$ at a small nonzero value (e.g., `1e-8`).\n",
    "- Remember that $p(\\mu_s | s_1, \\ldots, s_t) = \\int p(\\mu_s, \\sigma_s | s_1, \\ldots, s_t) d \\sigma_s$, and similarly $p(\\sigma_s | s_1, \\ldots, s_t) = \\int p(\\mu_s, \\sigma_s | s_1, \\ldots, s_t) d \\mu_s$. These equations will be useful to compute the posterior mean of $\\mu_s$ and $\\sigma_s$.\n",
    "- For part (b), first of all look at the distribution of stimuli (i.e., mean and standard deviation of $\\mathbf{s}$). How does the distribution of stimuli relate to the prior? What happens over time as more stimuli are seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t = np.array([ 0.4936518 ,  0.15823654,  0.17077424,  0.08905471,  0.37981114,\n",
    "       -0.0952308 ,  0.51172176,  0.13581896,  0.29785586,  0.21259444,\n",
    "        0.46931619, -0.05902111,  0.20163742,  0.19239185,  0.42006542,\n",
    "        0.08501631,  0.22413577,  0.11832124,  0.25633206,  0.33742228,\n",
    "        0.08490712,  0.42170856,  0.38523861,  0.32537415,  0.38512839,\n",
    "        0.14744082,  0.23156647,  0.10963458,  0.20981679,  0.32955332,\n",
    "        0.14625089,  0.19048697,  0.14692409,  0.12321915,  0.14931308,\n",
    "        0.24810031,  0.08240345,  0.28516235,  0.49897033,  0.36130662,\n",
    "        0.22122467,  0.11685566,  0.13792626,  0.50386819,  0.25762116,\n",
    "        0.15445065,  0.27863732,  0.56503827,  0.26802384,  0.34258047,\n",
    "        0.29502555,  0.19716252,  0.07862227,  0.19759859,  0.21866586,\n",
    "        0.33799348,  0.37584751,  0.38966531,  0.2928381 ,  0.38277117,\n",
    "        0.13684031,  0.43793022,  0.32693947,  0.20528607,  0.32327772,\n",
    "        0.23866424,  0.41974441,  0.47797252,  0.57783631,  0.04052555,\n",
    "        0.03338293,  0.17433012,  0.27400556,  0.38142534,  0.29734524,\n",
    "       -0.05333018,  0.2040694 ,  0.3741962 ,  0.28451421,  0.36430168,\n",
    "        0.21665078,  0.21988629,  0.27798421,  0.31150775,  0.27974496,\n",
    "        0.2678513 ,  0.14940066,  0.30663457,  0.26827319,  0.41942259,\n",
    "        0.42983768,  0.27777346,  0.19370726,  0.15419044,  0.31352415,\n",
    "        0.26160101,  0.19842195,  0.25653953,  0.15699987,  0.35470481])\n",
    "\n",
    "T = s_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The posterior mean of the observer's prior mean is 0.2557116929623856\n",
      "The posterior mean of the observer's prior standard deviation is 0.13660216418794532\n"
     ]
    }
   ],
   "source": [
    "# Prior parameters\n",
    "tau = 0.1\n",
    "\n",
    "# Adjust discretization of mu_s and sigma_s\n",
    "mu_s_values = np.linspace(-1, 1, 2**6 + 1)\n",
    "sigma_s_values = np.linspace(1e-8, 1, 2**6 + 1)\n",
    "\n",
    "# Create a meshgrid for mu_s and sigma_s\n",
    "mu_s_grid, sigma_s_grid = np.meshgrid(mu_s_values, sigma_s_values, indexing='ij')\n",
    "\n",
    "# Initialize the posterior as the prior\n",
    "posterior = sps.norm.pdf(mu_s_grid, loc=0, scale=tau) * (1/tau) * np.exp(-sigma_s_grid/tau)\n",
    "\n",
    "# Lists to store the posterior means\n",
    "mu_s_PM_list = []\n",
    "sigma_s_PM_list = []\n",
    "\n",
    "# Update the posterior based on observations and compute posterior means iteratively\n",
    "for s in s_t:\n",
    "    likelihood = sps.norm.pdf(s, loc=mu_s_grid, scale=sigma_s_grid)\n",
    "    posterior *= likelihood\n",
    "    posterior /= sp.integrate.romb(sp.integrate.romb(posterior, dx=np.diff(sigma_s_values)[0]), dx=np.diff(mu_s_values)[0])  # Normalize\n",
    "\n",
    "    # Compute and store the posterior means after each observation\n",
    "    mu_s_PM_num = sp.integrate.romb(sp.integrate.romb(mu_s_grid * posterior, dx=np.diff(sigma_s_values)[0]), dx=np.diff(mu_s_values)[0])\n",
    "    mu_s_PM = mu_s_PM_num / sp.integrate.romb(sp.integrate.romb(posterior, dx=np.diff(sigma_s_values)[0]), dx=np.diff(mu_s_values)[0])\n",
    "\n",
    "    sigma_s_PM_num = sp.integrate.romb(sp.integrate.romb(sigma_s_grid * posterior, dx=np.diff(mu_s_values)[0]), dx=np.diff(sigma_s_values)[0])\n",
    "    sigma_s_PM = sigma_s_PM_num / sp.integrate.romb(sp.integrate.romb(posterior, dx=np.diff(mu_s_values)[0]), dx=np.diff(sigma_s_values)[0])\n",
    "\n",
    "    mu_s_PM_list.append(mu_s_PM)\n",
    "    sigma_s_PM_list.append(sigma_s_PM)\n",
    "\n",
    "# Posterior mean of the observer's prior mean after T observations\n",
    "mu_s_PM = mu_s_PM_list[-1]\n",
    "\n",
    "# Posterior mean of the observer's prior standard deviation after T observations\n",
    "sigma_s_PM = sigma_s_PM_list[-1]\n",
    "\n",
    "print(\"The posterior mean of the observer's prior mean is {}\".format(mu_s_PM))\n",
    "print(\"The posterior mean of the observer's prior standard deviation is {}\".format(sigma_s_PM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot mu_s_PM\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(mu_s_PM_list) + 1), mu_s_PM_list, marker='o', linestyle='-')\n",
    "plt.title(r'Posterior Mean $\\mu_s^{PM}$ Over Time')\n",
    "plt.xlabel('Trial t')\n",
    "plt.ylabel(r'$\\mu_s^{PM}$')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot sigma_s_PM\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(sigma_s_PM_list) + 1), sigma_s_PM_list, marker='o', linestyle='-', color='red')\n",
    "plt.title(r'Posterior Mean $\\sigma_s^{PM}$ Over Time')\n",
    "plt.xlabel('Trial t')\n",
    "plt.ylabel(r'$\\sigma_s^{PM}$')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
